{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "root = logging.getLogger()\n",
    "root.setLevel(logging.INFO)\n",
    "\n",
    "handler = logging.StreamHandler(sys.stdout)\n",
    "handler.setLevel(logging.INFO)\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "handler.setFormatter(formatter)\n",
    "root.addHandler(handler)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-24T17:19:47.931616Z",
     "start_time": "2025-01-24T17:19:47.928037Z"
    }
   },
   "id": "8aa09bd916c44aac",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-24 20:19:48,553 - numexpr.utils - INFO - Note: NumExpr detected 32 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 16.\n",
      "2025-01-24 20:19:48,554 - numexpr.utils - INFO - NumExpr defaulting to 16 threads.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from scripts.path_findings import ch_builder\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append('../scripts')\n",
    "sys.path.append('../')\n",
    "\n",
    "from scripts import graph_osm_loader\n",
    "from scripts import pipeline, centroids_graph_builder, clustering\n",
    "from scripts.path_findings import excraction_pfa, dijkstra_pfa\n",
    "from scripts import utils"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-24T17:19:49.462371Z",
     "start_time": "2025-01-24T17:19:47.932888Z"
    }
   },
   "id": "47b67f71a2bc0ec7",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import pytorch_lightning as pl"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-24T17:19:51.662650Z",
     "start_time": "2025-01-24T17:19:49.464006Z"
    }
   },
   "id": "1750b00d673eda60",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "715 1038\n"
     ]
    }
   ],
   "source": [
    "GRAPH_ID = 'R13470549'  # R13470549 R2555133 R3766483\n",
    "# примеры id есть в graph_osm_loader.py\n",
    "g = graph_osm_loader.get_graph(GRAPH_ID)\n",
    "print(len(g.nodes), len(g.edges))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-24T17:19:51.670389Z",
     "start_time": "2025-01-24T17:19:51.663649Z"
    }
   },
   "id": "15eac780277049d7",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "find centroids:   0%|          | 0/269 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "83b63e3b78da4198aef5008674826c54"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "find edges:   0%|          | 0/269 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9441071174064bc9b8cb011306f166f9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "cms_resolver = clustering.LouvainCommunityResolver(resolution=100)\n",
    "\n",
    "t, cg = centroids_graph_builder.CentroidGraphBuilder().build_with_time(g, cms_resolver)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-24T17:19:51.892143Z",
     "start_time": "2025-01-24T17:19:51.671135Z"
    }
   },
   "id": "e085c25e5f6bef66",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "points = utils.read_points(GRAPH_ID, g, num=10000)\n",
    "data = []\n",
    "for p1, p2 in points:\n",
    "    path = nx.dijkstra_path_length(g, p1,p2,weight='length')\n",
    "    c1,c2 = g.nodes()[p1]['cluster'], g.nodes()[p2]['cluster']\n",
    "    vector1 = np.zeros(len(cg.g.nodes), dtype=np.float32)\n",
    "    vector2 = np.zeros(len(cg.g.nodes), dtype=np.float32)\n",
    "    vector1[c1]=1\n",
    "    vector1[c2]=1\n",
    "    data.append((vector1,np.array([path], dtype=np.float32)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-24T15:53:18.064628Z",
     "start_time": "2025-01-24T15:53:14.834996Z"
    }
   },
   "id": "32ca7f6a7280fdaa",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from scripts.path_findings.h_search_builder import MinClusterDistance\n",
    "import torch\n",
    "alg = MinClusterDistance(workers=20).build_astar(g, cms_resolver) \n",
    "a = alg.h.d_cluster\n",
    "\n",
    "U,S,V = np.linalg.svd(a, full_matrices=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-24T17:43:01.447311Z",
     "start_time": "2025-01-24T17:43:01.176194Z"
    }
   },
   "id": "5a3dab42c260f37b",
   "execution_count": 55
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-24T17:43:01.493720Z",
     "start_time": "2025-01-24T17:43:01.487672Z"
    }
   },
   "id": "c769daaeb12180f0",
   "execution_count": 55
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "k = 2 \n",
    "uk = U[:,:k]\n",
    "sk = np.diag(S[:k])\n",
    "vk = V[:k,:]\n",
    "\n",
    "aa = uk @ sk @ vk\n",
    "alg.h.d_cluster = aa"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-24T17:43:01.990764Z",
     "start_time": "2025-01-24T17:43:01.987442Z"
    }
   },
   "id": "6f86add1ed830b73",
   "execution_count": 56
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.8814e+17, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "tensor(1.5501e+31, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "tensor(2.0474e+72, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "tensor(3.0953e+195, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "tensor(inf, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "tensor(inf, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<PowBackward0>)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<PowBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from scripts.path_findings.h_search_builder import MinClusterDistance\n",
    "import torch\n",
    "Q = 10000\n",
    "a = torch.tensor(MinClusterDistance(workers=20).build_astar(g, cms_resolver).h.d_cluster, dtype=torch.float64)\n",
    "x = torch.ones((len(a), Q),requires_grad=True, dtype=torch.float64)\n",
    "y = torch.ones((Q, len(a)),requires_grad=True, dtype=torch.float64)\n",
    "alpha = 0.00000001\n",
    "b = 0.9\n",
    "for i in range(15):\n",
    "    aa = torch.mm(x,y)\n",
    "    loss = torch.sum(aa-a)**2\n",
    "    print(loss)\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        x -=x.grad * alpha\n",
    "        y -=y.grad * alpha\n",
    "    x.grad.data.zero_()\n",
    "    y.grad.data.zero_()\n",
    "    alpha*=b\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-24T17:34:09.118370Z",
     "start_time": "2025-01-24T17:34:08.387628Z"
    }
   },
   "id": "afae4b20130305ed",
   "execution_count": 52
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "\n",
    "class FacePointDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        super(Dataset, self).__init__()\n",
    "        self.data = data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        f,g  = data[idx]\n",
    "        return torch.from_numpy(f), torch.tensor(g) "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-24T15:53:18.632550Z",
     "start_time": "2025-01-24T15:53:18.630333Z"
    }
   },
   "id": "6ddc930986b05c47",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "\n",
    "class MyModel(nn.Sequential):\n",
    "    def __init__(self, num_points=len(cg.g.nodes)):\n",
    "        super().__init__()\n",
    "        self.ln = nn.Linear(num_points, 2000)\n",
    "        self.rl = nn.ReLU()\n",
    "        self.ln1 = nn.Linear(2000, 1)\n",
    "    # def forward(self, input):\n",
    "    #     print(input.shape)\n",
    "    #     input = self.ln"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-24T15:53:19.097736Z",
     "start_time": "2025-01-24T15:53:19.095226Z"
    }
   },
   "id": "9de1b2a0180e490",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import torchmetrics\n",
    "\n",
    "\n",
    "class MyModelTrainer(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = MyModel()\n",
    "        self.metrics = torchmetrics.MeanSquaredError(squared=True)\n",
    "        self.loss = nn.MSELoss()\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y_gt = batch\n",
    "        y_pr = self.model(x)\n",
    "        loss = self.loss(y_pr, y_gt)\n",
    "        metrics = {\"train_loss\": loss}\n",
    "        self.log_dict(metrics, prog_bar=True, on_step=True, on_epoch=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y_gt = batch\n",
    "        y_pr = self.model(x)\n",
    "        \n",
    "        loss = self.metrics(y_pr, y_gt)\n",
    "        metrics = {\"valid_loss\": loss}\n",
    "        self.log_dict(metrics, prog_bar=True, on_step=True, on_epoch=True, logger=True)\n",
    "        return metrics\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"\"\"Define optimizers and LR schedulers.\"\"\"\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3, weight_decay=5e-4)\n",
    "        #optimizer = torch.optim.SGD(self.model.parameters(), lr=1e-3, momentum=0.9)\n",
    "\n",
    "        lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(\n",
    "            optimizer,\n",
    "            gamma=0.95\n",
    "        )\n",
    "        lr_dict = {\n",
    "            # The scheduler instance\n",
    "            \"scheduler\": lr_scheduler,\n",
    "            # The unit of the scheduler's step size, could also be 'step'.\n",
    "            # 'epoch' updates the scheduler on epoch end whereas 'step'\n",
    "            # updates it after a optimizer update.\n",
    "            \"interval\": \"epoch\",\n",
    "            # How many epochs/steps should pass between calls to\n",
    "            # `scheduler.step()`. 1 corresponds to updating the learning\n",
    "            # rate after every epoch/step.\n",
    "            \"frequency\": 1,\n",
    "            # Metric to to monitor for schedulers like `ReduceLROnPlateau`\n",
    "            \"monitor\": \"train_loss\",\n",
    "        }\n",
    "\n",
    "        return [optimizer], [lr_dict]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-24T15:53:19.325446Z",
     "start_time": "2025-01-24T15:53:19.321986Z"
    }
   },
   "id": "1a4d259ceef688f9",
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "'cuda'"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = 'cuda'  if torch.cuda.is_available() else 'cpu'\n",
    "DEVICE"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-24T15:53:19.575439Z",
     "start_time": "2025-01-24T15:53:19.572208Z"
    }
   },
   "id": "df7f43989c09097a",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-24T17:05:37.263014Z",
     "start_time": "2025-01-24T17:05:36.949697Z"
    }
   },
   "id": "ca59f1ccc9838fb7",
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train():\n",
    "    dataset = FacePointDataset()\n",
    "    \n",
    "    train, valid = torch.utils.data.random_split(dataset, [0.9, 0.1])\n",
    "    \n",
    "    dl_train = DataLoader(train, batch_size=30, shuffle=True, num_workers=4, persistent_workers=True)\n",
    "    dl_valid = DataLoader(valid, batch_size=10, shuffle=False, num_workers=4, persistent_workers=True)\n",
    "    \n",
    "    model = MyModelTrainer()\n",
    "    \n",
    "    trainer = pl.Trainer(\n",
    "            accelerator=DEVICE,\n",
    "            devices=1,\n",
    "            max_epochs=20,\n",
    "            log_every_n_steps=5)\n",
    "    trainer.fit(model, dl_train, dl_valid)\n",
    "    \n",
    "    torch.save(model.model.state_dict(), '../data/models/model.ckpt')\n",
    "    \n",
    "    return model.model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-24T15:53:19.797682Z",
     "start_time": "2025-01-24T15:53:19.792039Z"
    }
   },
   "id": "8edac20f607ad3fb",
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-24 18:53:19,948 - pytorch_lightning.utilities.rank_zero - INFO - GPU available: True (cuda), used: True\n",
      "2025-01-24 18:53:19,949 - pytorch_lightning.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores\n",
      "2025-01-24 18:53:19,949 - pytorch_lightning.utilities.rank_zero - INFO - HPU available: False, using: 0 HPUs\n",
      "2025-01-24 18:53:19,951 - pytorch_lightning.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "2025-01-24 18:53:19,966 - pytorch_lightning.callbacks.model_summary - INFO - \n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | MyModel          | 542 K  | train\n",
      "1 | metrics | MeanSquaredError | 0      | train\n",
      "2 | loss    | MSELoss          | 0      | train\n",
      "-----------------------------------------------------\n",
      "542 K     Trainable params\n",
      "0         Non-trainable params\n",
      "542 K     Total params\n",
      "2.168     Total estimated model params size (MB)\n",
      "6         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "text/plain": "Sanity Checking: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ec38033e173b46608928e90e7bc301c7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Training: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ddb6c8a63a2146c78fd278e73c0f8631"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6f9abed9872e4e8e877436b6494a168f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d89c50c108464b579c5e8e9f011042ce"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3f4e9d1461714bcaa7720389548d7986"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d2a0e38ddad44d6683a563440b47903f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "76907a87041443d687ca490b5ffd6ca7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "98c805693d4c4d3882a069f949608be9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5ec26008f8c84c51803bbe7be9641de6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0eeaa4a5e757422a9a6f7cfb518221e9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5905401a00f74721a8a5701865981d69"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "aa37593431a5451b9345bde11eea771f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "m = train()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-24T15:53:37.218557Z",
     "start_time": "2025-01-24T15:53:19.939504Z"
    }
   },
   "id": "879f2ad4697d7c16",
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "x = m(torch.from_numpy(data[90][0]).unsqueeze(0)).detach().numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-24T15:56:34.007439Z",
     "start_time": "2025-01-24T15:56:34.004982Z"
    }
   },
   "id": "429e40edece83626",
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "array([[4007.9956]], dtype=float32)"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-24T15:56:34.633827Z",
     "start_time": "2025-01-24T15:56:34.631141Z"
    }
   },
   "id": "78da7ede9bfb0c38",
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "args = np.argwhere(x >= 0.5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-24T15:14:51.535275Z",
     "start_time": "2025-01-24T15:14:51.531343Z"
    }
   },
   "id": "bd363613f92d2980",
   "execution_count": 211
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "array([[  0,   0],\n       [  0,   1],\n       [  0,   2],\n       [  0,   3],\n       [  0,   7],\n       [  0,   8],\n       [  0,   9],\n       [  0,  10],\n       [  0,  11],\n       [  0,  15],\n       [  0,  16],\n       [  0,  27],\n       [  0,  51],\n       [  0,  69],\n       [  0,  94],\n       [  0,  95],\n       [  0,  96],\n       [  0,  97],\n       [  0,  98],\n       [  0, 102],\n       [  0, 103],\n       [  0, 176],\n       [  0, 178],\n       [  0, 180],\n       [  0, 183],\n       [  0, 184],\n       [  0, 191],\n       [  0, 192],\n       [  0, 193],\n       [  0, 194],\n       [  0, 195],\n       [  0, 221],\n       [  0, 225],\n       [  0, 226],\n       [  0, 232],\n       [  0, 233],\n       [  0, 234],\n       [  0, 237],\n       [  0, 238],\n       [  0, 248],\n       [  0, 256],\n       [  0, 257],\n       [  0, 261],\n       [  0, 263],\n       [  0, 266]])"
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-24T15:14:52.065806Z",
     "start_time": "2025-01-24T15:14:52.062033Z"
    }
   },
   "id": "94ce5c4444587d4d",
   "execution_count": 212
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(45, np.float32(9.0))"
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(args), sum(data[0][1])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-24T15:14:55.567771Z",
     "start_time": "2025-01-24T15:14:55.562626Z"
    }
   },
   "id": "2a23bb2c6f2ccdf6",
   "execution_count": 213
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "5306954570",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[214], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mscripts\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpath_findings\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m dijkstra_pfa\n\u001B[1;32m      2\u001B[0m d \u001B[38;5;241m=\u001B[39m dijkstra_pfa\u001B[38;5;241m.\u001B[39mDijkstra(g)\n\u001B[0;32m----> 3\u001B[0m \u001B[43md\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfind_path_cls\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpoints\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43mpoints\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcms\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43mset\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mint\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43ma\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43ma\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/programming/graph_clustering/scripts/path_findings/dijkstra_pfa.py:47\u001B[0m, in \u001B[0;36mDijkstra.find_path_cls\u001B[0;34m(self, start, end, cms)\u001B[0m\n\u001B[1;32m     45\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m u \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m dist:\n\u001B[1;32m     46\u001B[0m             push(fringe, (vu_dist, \u001B[38;5;28mnext\u001B[39m(c), n \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m, u, v))\n\u001B[0;32m---> 47\u001B[0m d, n \u001B[38;5;241m=\u001B[39m \u001B[43mdist\u001B[49m\u001B[43m[\u001B[49m\u001B[43mend\u001B[49m\u001B[43m]\u001B[49m\n\u001B[1;32m     48\u001B[0m n \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m     49\u001B[0m path \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28;01mNone\u001B[39;00m] \u001B[38;5;241m*\u001B[39m n\n",
      "\u001B[0;31mKeyError\u001B[0m: 5306954570"
     ]
    }
   ],
   "source": [
    "from scripts.path_findings import dijkstra_pfa\n",
    "d = dijkstra_pfa.Dijkstra(g)\n",
    "d.find_path_cls(points[0][0],points[0][1], cms = set([int(a[0]) for a in args]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-24T15:14:56.564465Z",
     "start_time": "2025-01-24T15:14:56.545088Z"
    }
   },
   "id": "638cbfe3edceb1c2",
   "execution_count": 214
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "np.float64(5075.117000000001)"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.dijkstra_path_length(g,points[90][0], points[90][1], weight='length')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-24T15:56:42.954768Z",
     "start_time": "2025-01-24T15:56:42.951975Z"
    }
   },
   "id": "fb5ed7c095792285",
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "8e5333fefd3370b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
