{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os.path\n",
    "import random\n",
    "import time\n",
    "from time import sleep\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "import osmnx as ox\n",
    "import pandas as pd\n",
    "from tqdm.notebook import trange, tqdm\n",
    "import pickle\n",
    "import os\n",
    "import itertools\n",
    "import folium\n",
    "from matplotlib import pyplot as plt\n",
    "from multiprocessing import Pool"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-16T09:50:36.096150Z",
     "start_time": "2024-10-16T09:50:32.690234Z"
    }
   },
   "id": "initial_id",
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "b3a8bf6d68200a29"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Statistic for all-pair-paths between points of two clusters\n",
    "def get_statistic_per_point(graph: nx.Graph, c_from: int, c_to: int, _cls2hubs: dict[int:set[int]], log=False):\n",
    "    nodes_from = _cls2hubs[c_from]\n",
    "    nodes_to = _cls2hubs[c_to]\n",
    "    statistic = {}\n",
    "    iter = itertools.product(nodes_from, nodes_to)\n",
    "    generator = tqdm(iter, desc='find statistic', total=len(nodes_to) * len(nodes_from)) if log else iter\n",
    "    for f,t in generator:\n",
    "        p = nx.single_source_dijkstra(graph, f, t, weight='length')\n",
    "        cls = list(dict.fromkeys([int(graph.nodes()[u]['cluster']) for u in p[1]]))\n",
    "        cls = tuple(cls)\n",
    "        if cls not in statistic:\n",
    "            statistic[cls] = 0\n",
    "        statistic[cls] += 1\n",
    "    return statistic"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-16T09:50:36.107891Z",
     "start_time": "2024-10-16T09:50:36.099054Z"
    }
   },
   "id": "6c9b2ee661caaab7",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# cluster to neighboring clusters\n",
    "def get_cls2n(graph: nx.Graph) -> dict[int: set[int]]:\n",
    "    _cls2n = {}\n",
    "    for u, du in graph.nodes(data=True):\n",
    "        for v in graph[u]:\n",
    "            dv = graph.nodes()[v]\n",
    "            if dv['cluster'] == du['cluster']:\n",
    "                continue\n",
    "            c1 = dv['cluster']\n",
    "            c2 = du['cluster']\n",
    "            if not (c1 in _cls2n):\n",
    "                _cls2n[c1] = set()\n",
    "            if not (c2 in _cls2n):\n",
    "                _cls2n[c2] = set()\n",
    "            _cls2n[c1].add(c2)\n",
    "            _cls2n[c2].add(c1)\n",
    "    return _cls2n\n",
    "\n",
    "\n",
    "# cluster then yts point that are connected with neighboring clusters\n",
    "def get_cls2hubs(graph: nx.Graph) -> dict[int: set[int]]:\n",
    "    _cls2hubs = {}\n",
    "    for u, du in graph.nodes(data=True):\n",
    "        for v in graph[u]:\n",
    "            dv = graph.nodes()[v]\n",
    "            c1 = du['cluster']\n",
    "            c2 = dv['cluster']\n",
    "            if c1 == c2:\n",
    "                continue\n",
    "            if not (c1 in _cls2hubs):\n",
    "                _cls2hubs[c1] = set()\n",
    "            if not (c2 in _cls2hubs):\n",
    "                _cls2hubs[c2] = set()\n",
    "            _cls2hubs[c1].add(u)\n",
    "            _cls2hubs[c2].add(v)\n",
    "    return _cls2hubs\n",
    "\n",
    "# функция для параллельного вычисления матрицы смежности\n",
    "def do_ad_mat(data):\n",
    "    g , points, cls2n , cls2hubs, worker = data.values()\n",
    "    ad_matrix={}\n",
    "    sleep(worker/10)\n",
    "    print(f'start: {worker}')\n",
    "    for i in tqdm(points, total=len(points), position=worker, desc=f'build ad_matrix, work:{worker}'):\n",
    "        ad_matrix[i] = {}\n",
    "        for j in set(cls2n[i]).union({i}):\n",
    "            data = get_statistic_per_point(g, i, j, cls2hubs, False)\n",
    "            cls0to1 = set()\n",
    "            for k, v in data.items():\n",
    "                for kk in k:\n",
    "                    cls0to1.add(kk)\n",
    "            ad_matrix[i][j] = cls0to1\n",
    "    return ad_matrix\n",
    "\n",
    "\n",
    "# adjacency matrix. it contains clusters that intersect with paths between two clusters\n",
    "def get_ad_matrix(\n",
    "        graph: nx.Graph,\n",
    "        communities: list[set[int]],\n",
    "        cls2hubs,\n",
    "        cls2n,\n",
    "        WORKERS = 4\n",
    ") -> dict[int: dict[int:set[int]]]:\n",
    "    ad_matrix = {}\n",
    "    \n",
    "    data = [{\n",
    "        'g': graph,\n",
    "        'points': [i for i in range(worker, len(communities), WORKERS)],\n",
    "        'cls2n': cls2n,\n",
    "        'cls2hubs': cls2hubs,\n",
    "        'worker': worker\n",
    "    } for worker in range(WORKERS)]\n",
    "    with Pool(WORKERS) as p:\n",
    "        res = p.map(do_ad_mat, data)\n",
    "    for r in res:\n",
    "        for i in r:\n",
    "            if i not in ad_matrix:\n",
    "                ad_matrix[i] = {}\n",
    "            for j in r[i]:\n",
    "                ad_matrix[i][j] = r[i][j]\n",
    "    return ad_matrix\n",
    "\n",
    "def get_r(_g:nx.Graph, u:int)->float:\n",
    "    nodes = len(_g.nodes())\n",
    "    summ_d = 0\n",
    "    paths = nx.shortest_path_length(_g, u, weight='length')\n",
    "    for _,l in paths.items():\n",
    "        summ_d+=l\n",
    "    return summ_d/nodes\n",
    "\n",
    "def get_min_dst(_g:nx.Graph, c1:int, c2:int)->float:\n",
    "    m = float('inf')\n",
    "    for u, du in _g.nodes(data=True):\n",
    "        if du['cluster']!=c1:\n",
    "            continue\n",
    "        for v,d in _g[u].items():\n",
    "            dv = _g.nodes()[v]\n",
    "            if dv['cluster']!=c2:\n",
    "                continue\n",
    "            l = d['length']\n",
    "            if l <m:\n",
    "                m=l\n",
    "    return m\n",
    "# build_center_graph\n",
    "def build_center_graph(\n",
    "        graph: nx.Graph,\n",
    "        communities: list[set[int]],\n",
    "        adjacency: dict[int:dict[int, set[int]]],\n",
    "        cls2n: dict[int: set[int]]\n",
    ") -> tuple[nx.Graph, dict[int, int]]:\n",
    "    x_graph = nx.Graph()\n",
    "    cls2c = {}\n",
    "    for cls, _ in tqdm(enumerate(communities), total=len(communities), desc='find centroids'):\n",
    "        gc = extract_cluster_list_subgraph(graph, [cls], communities)\n",
    "        min_node = nx.barycenter(gc, weight='length')[0]\n",
    "        du = graph.nodes()[min_node]\n",
    "        x_graph.add_node(graph.nodes()[min_node]['cluster'], **du)\n",
    "        cls2c[graph.nodes()[min_node]['cluster']] = min_node\n",
    "\n",
    "    if len(x_graph.nodes) == 1:\n",
    "        return x_graph, cls2c\n",
    "    \n",
    "    for u in tqdm(x_graph.nodes(), desc = 'find edges'):\n",
    "        for v in cls2n[u]:\n",
    "            g = extract_cluster_list_subgraph(graph, adjacency[u][v], communities)\n",
    "            l = nx.single_source_dijkstra(g, source=cls2c[u], target=cls2c[v], weight='length')[0]\n",
    "            # ll = get_min_dst(graph, u,v) \n",
    "            # ll_u = get_r(extract_cluster_list_subgraph(graph, [u], communities), cls2c[u])\n",
    "            # ll_v = get_r(extract_cluster_list_subgraph(graph, [v], communities), cls2c[v])\n",
    "            # print(l, ll, ll_u,ll_v, ll+ll_u+ll_v)\n",
    "            x_graph.add_edge(u, v, length=l)\n",
    "    return x_graph, cls2c\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-16T09:50:36.137172Z",
     "start_time": "2024-10-16T09:50:36.109970Z"
    }
   },
   "id": "236db12a822b1cb6",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "9d2b696ee716410a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#load graph\n",
    "def get_graph(city_id: str = 'R2555133') -> nx.Graph:\n",
    "    gdf = ox.geocode_to_gdf(city_id, by_osmid=True)\n",
    "    polygon_boundary = gdf.unary_union\n",
    "    graph = ox.graph_from_polygon(polygon_boundary,\n",
    "                                  network_type='drive',\n",
    "                                  simplify=True)\n",
    "    G = nx.Graph(graph)\n",
    "    H = nx.Graph()\n",
    "    # Добавляем рёбра в новый граф, копируя только веса\n",
    "    for u, d in G.nodes(data=True):\n",
    "        H.add_node(u, x=d['x'], y=d['y'])\n",
    "    for u, v, d in G.edges(data=True):\n",
    "        if u == v:\n",
    "            continue\n",
    "        da=H.nodes()[u]\n",
    "        db=H.nodes()[v]\n",
    "        # H.add_edge(u, v, length=((da['x'] - db['x']) ** 2 + (da['y'] - db['y']) ** 2) ** 0.5 / 360 * 2 * np.pi * 6371.01 * 1000)\n",
    "        H.add_edge(u, v, length=d['length'])\n",
    "    del city_id, gdf, polygon_boundary, graph, G\n",
    "    return H\n",
    "\n",
    "#extract subgraph by clusters\n",
    "def extract_cluster_list_subgraph(graph: nx.Graph, cluster_number: list[int] | set[int], communities=None) -> nx.Graph:\n",
    "    if communities:\n",
    "        nodes_to_keep = [u for c in cluster_number for u in communities[c]]\n",
    "    else:\n",
    "        nodes_to_keep = [node for node, data in graph.nodes(data=True) if data['cluster'] in cluster_number]\n",
    "    return graph.subgraph(nodes_to_keep)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-16T09:50:39.418842Z",
     "start_time": "2024-10-16T09:50:39.411640Z"
    }
   },
   "id": "769b8cceb07d0805",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans, DBSCAN, HDBSCAN, BisectingKMeans\n",
    "\n",
    "\n",
    "#resolve_communities\n",
    "def resolve_communities(H: nx.Graph, **params) -> list[set[int]]:\n",
    "    communities = nx.community.louvain_communities(H,\n",
    "                                                   seed=1534,\n",
    "                                                   weight='length',\n",
    "                                                   resolution=params['r'])\n",
    "    cls = []\n",
    "    for i, c in enumerate(communities):\n",
    "        for n in nx.connected_components(H.subgraph(c)):\n",
    "            cls.append(n)\n",
    "    for i, ids in enumerate(cls):\n",
    "        for j in ids:\n",
    "            H.nodes()[j]['cluster'] = i\n",
    "    return cls\n",
    "\n",
    "def resolve_by_hdbscan(H: nx.Graph):\n",
    "    paths = dict(tqdm(nx.all_pairs_dijkstra_path_length(H, weight='length'), total=(len(H.nodes()))))\n",
    "    def f(a,b):\n",
    "        u = int(a[2])\n",
    "        v = int(b[2])\n",
    "        return paths[u][v]\n",
    "        # if (u,v) in H.edges() or (v,u) in H.edges():\n",
    "        #     return H.edges()[(u,v)]['length']\n",
    "        # return float('inf')\n",
    "        # return nx.single_source_dijkstra(g, u,v,weight='length')[0]\n",
    "    scan = HDBSCAN(metric=f, min_samples=1, max_cluster_size=30,n_jobs=-1,store_centers='medoid')\n",
    "    x = np.array([[d['x'], d['y'], u] for u, d in g.nodes(data=True)])\n",
    "    y = scan.fit_predict(x)\n",
    "    communities = {}\n",
    "    for i, u in enumerate(g.nodes):\n",
    "        cls = y[i]\n",
    "        if cls not in communities:\n",
    "            communities[cls] = set()\n",
    "        communities[cls].add(u)\n",
    "    communities = [communities[cls] for cls in communities]\n",
    "    cls = []\n",
    "    for i, c in enumerate(communities):\n",
    "        for n in nx.connected_components(g.subgraph(c)):\n",
    "            cls.append(n)\n",
    "    for i, ids in enumerate(cls):\n",
    "        for j in ids:\n",
    "            H.nodes()[j]['cluster'] = i\n",
    "    del scan\n",
    "    return cls"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-16T09:50:40.872195Z",
     "start_time": "2024-10-16T09:50:40.715725Z"
    }
   },
   "id": "3546eec44b2bc0ae",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(17923, 27016)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# примеры id есть в test_city.py\n",
    "g = get_graph('R2555133')\n",
    "len(g.nodes), len(g.edges)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-16T09:51:16.779080Z",
     "start_time": "2024-10-16T09:50:42.791950Z"
    }
   },
   "id": "b219e78cf93171f5",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "588676292 {'length': 21.732}\n",
      "12067885511 {'length': 177.201}\n",
      "12067885520 {'length': 29.774}\n"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-16T07:58:30.234023Z",
     "start_time": "2024-10-16T07:58:30.228679Z"
    }
   },
   "id": "458d55e381ef6570",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# оптимальное количество кластеров из статьи\n",
    "def get_opt_cluster_count(nodes:int)-> int:\n",
    "    alpha = 8.09 * (nodes ** (-0.48)) * (1 - 19.4 / (4.8 * np.log(nodes) + 8.8)) * nodes\n",
    "    return int(alpha) "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5e8b209b84edc412",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "88b1e8db57eccb6a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "get_opt_cluster_count(len(g.nodes))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b1053ecba87c88b6",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/17923 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dd1fb9e5f38240f49712b9a3aa3cbb5b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "    \u001B[0;31m[... skipping hidden 1 frame]\u001B[0m\n",
      "Cell \u001B[0;32mIn[7], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# cms1 = resolve_communities(g, r=26)\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m cms \u001B[38;5;241m=\u001B[39m \u001B[43mresolve_by_hdbscan\u001B[49m\u001B[43m(\u001B[49m\u001B[43mg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;28mlen\u001B[39m(cms))\n",
      "Cell \u001B[0;32mIn[5], line 20\u001B[0m, in \u001B[0;36mresolve_by_hdbscan\u001B[0;34m(H)\u001B[0m\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mresolve_by_hdbscan\u001B[39m(H: nx\u001B[38;5;241m.\u001B[39mGraph):\n\u001B[0;32m---> 20\u001B[0m     paths \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mdict\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mtqdm\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mall_pairs_dijkstra_path_length\u001B[49m\u001B[43m(\u001B[49m\u001B[43mH\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mlength\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtotal\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mH\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnodes\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     21\u001B[0m     \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mf\u001B[39m(a,b):\n",
      "File \u001B[0;32m~/graph_clustering/.venv/lib/python3.10/site-packages/tqdm/notebook.py:250\u001B[0m, in \u001B[0;36mtqdm_notebook.__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    249\u001B[0m it \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__iter__\u001B[39m()\n\u001B[0;32m--> 250\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m obj \u001B[38;5;129;01min\u001B[39;00m it:\n\u001B[1;32m    251\u001B[0m     \u001B[38;5;66;03m# return super(tqdm...) will not catch exception\u001B[39;00m\n\u001B[1;32m    252\u001B[0m     \u001B[38;5;28;01myield\u001B[39;00m obj\n",
      "File \u001B[0;32m~/graph_clustering/.venv/lib/python3.10/site-packages/tqdm/std.py:1181\u001B[0m, in \u001B[0;36mtqdm.__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1180\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1181\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m obj \u001B[38;5;129;01min\u001B[39;00m iterable:\n\u001B[1;32m   1182\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m obj\n",
      "File \u001B[0;32m~/graph_clustering/.venv/lib/python3.10/site-packages/networkx/algorithms/shortest_paths/weighted.py:1085\u001B[0m, in \u001B[0;36mall_pairs_dijkstra_path_length\u001B[0;34m(G, cutoff, weight)\u001B[0m\n\u001B[1;32m   1084\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m n \u001B[38;5;129;01min\u001B[39;00m G:\n\u001B[0;32m-> 1085\u001B[0m     \u001B[38;5;28;01myield\u001B[39;00m (n, \u001B[43mlength\u001B[49m\u001B[43m(\u001B[49m\u001B[43mG\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcutoff\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcutoff\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[0;32m<class 'networkx.utils.decorators.argmap'> compilation 30:3\u001B[0m, in \u001B[0;36margmap_single_source_dijkstra_path_length_27\u001B[0;34m(G, source, cutoff, weight, backend, **backend_kwargs)\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mcollections\u001B[39;00m\n\u001B[0;32m----> 3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mgzip\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01minspect\u001B[39;00m\n",
      "File \u001B[0;32m~/graph_clustering/.venv/lib/python3.10/site-packages/networkx/utils/backends.py:633\u001B[0m, in \u001B[0;36m_dispatchable.__call__\u001B[0;34m(self, backend, *args, **kwargs)\u001B[0m\n\u001B[1;32m    631\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m backends:\n\u001B[1;32m    632\u001B[0m     \u001B[38;5;66;03m# Fast path if no backends are installed\u001B[39;00m\n\u001B[0;32m--> 633\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43morig_func\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    635\u001B[0m \u001B[38;5;66;03m# Use `backend_name` in this function instead of `backend`\u001B[39;00m\n",
      "File \u001B[0;32m~/graph_clustering/.venv/lib/python3.10/site-packages/networkx/algorithms/shortest_paths/weighted.py:389\u001B[0m, in \u001B[0;36msingle_source_dijkstra_path_length\u001B[0;34m(G, source, cutoff, weight)\u001B[0m\n\u001B[1;32m    322\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Find shortest weighted path lengths in G from a source node.\u001B[39;00m\n\u001B[1;32m    323\u001B[0m \n\u001B[1;32m    324\u001B[0m \u001B[38;5;124;03mCompute the shortest path length between source and all other\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    387\u001B[0m \n\u001B[1;32m    388\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m--> 389\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmulti_source_dijkstra_path_length\u001B[49m\u001B[43m(\u001B[49m\u001B[43mG\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[43msource\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcutoff\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcutoff\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m<class 'networkx.utils.decorators.argmap'> compilation 34:3\u001B[0m, in \u001B[0;36margmap_multi_source_dijkstra_path_length_31\u001B[0;34m(G, sources, cutoff, weight, backend, **backend_kwargs)\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mcollections\u001B[39;00m\n\u001B[0;32m----> 3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mgzip\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01minspect\u001B[39;00m\n",
      "File \u001B[0;32m~/graph_clustering/.venv/lib/python3.10/site-packages/networkx/utils/backends.py:633\u001B[0m, in \u001B[0;36m_dispatchable.__call__\u001B[0;34m(self, backend, *args, **kwargs)\u001B[0m\n\u001B[1;32m    631\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m backends:\n\u001B[1;32m    632\u001B[0m     \u001B[38;5;66;03m# Fast path if no backends are installed\u001B[39;00m\n\u001B[0;32m--> 633\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43morig_func\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    635\u001B[0m \u001B[38;5;66;03m# Use `backend_name` in this function instead of `backend`\u001B[39;00m\n",
      "File \u001B[0;32m~/graph_clustering/.venv/lib/python3.10/site-packages/networkx/algorithms/shortest_paths/weighted.py:647\u001B[0m, in \u001B[0;36mmulti_source_dijkstra_path_length\u001B[0;34m(G, sources, cutoff, weight)\u001B[0m\n\u001B[1;32m    646\u001B[0m weight \u001B[38;5;241m=\u001B[39m _weight_function(G, weight)\n\u001B[0;32m--> 647\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_dijkstra_multisource\u001B[49m\u001B[43m(\u001B[49m\u001B[43mG\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msources\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcutoff\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcutoff\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/graph_clustering/.venv/lib/python3.10/site-packages/networkx/algorithms/shortest_paths/weighted.py:853\u001B[0m, in \u001B[0;36m_dijkstra_multisource\u001B[0;34m(G, sources, weight, pred, paths, cutoff, target)\u001B[0m\n\u001B[1;32m    852\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m v \u001B[38;5;129;01min\u001B[39;00m dist:\n\u001B[0;32m--> 853\u001B[0m     \u001B[38;5;28;01mcontinue\u001B[39;00m  \u001B[38;5;66;03m# already searched this node.\u001B[39;00m\n\u001B[1;32m    854\u001B[0m dist[v] \u001B[38;5;241m=\u001B[39m d\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# cms1 = resolve_communities(g, r=26)\n",
    "cms = resolve_by_hdbscan(g)\n",
    "print(len(cms))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-16T09:57:08.609358Z",
     "start_time": "2024-10-16T09:51:16.781037Z"
    }
   },
   "id": "23c1a5d32d570651",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "8fc7f94a7b1dd0bf"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "cls2n = get_cls2n(g)\n",
    "cls2hubs = get_cls2hubs(g)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-16T09:28:12.266994Z",
     "start_time": "2024-10-16T09:28:12.134639Z"
    }
   },
   "id": "e6594fe741a815f3",
   "execution_count": 71
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/695556 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7f9a59d86734408099f9f816d7530eb5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[72], line 6\u001B[0m\n\u001B[1;32m      4\u001B[0m other \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m n,(i,j) \u001B[38;5;129;01min\u001B[39;00m tqdm(\u001B[38;5;28menumerate\u001B[39m(\u001B[38;5;28miter\u001B[39m), total \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(cms1)\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m2\u001B[39m):\n\u001B[0;32m----> 6\u001B[0m     stat \u001B[38;5;241m=\u001B[39m \u001B[43mget_statistic_per_point\u001B[49m\u001B[43m(\u001B[49m\u001B[43mg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mi\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcls2hubs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m      7\u001B[0m     total \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msum\u001B[39m([x[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m stat\u001B[38;5;241m.\u001B[39mitems()])\n\u001B[1;32m      8\u001B[0m     stat \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(stat\u001B[38;5;241m.\u001B[39mitems())\n",
      "Cell \u001B[0;32mIn[2], line 9\u001B[0m, in \u001B[0;36mget_statistic_per_point\u001B[0;34m(graph, c_from, c_to, _cls2hubs, log)\u001B[0m\n\u001B[1;32m      7\u001B[0m generator \u001B[38;5;241m=\u001B[39m tqdm(\u001B[38;5;28miter\u001B[39m, desc\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfind statistic\u001B[39m\u001B[38;5;124m'\u001B[39m, total\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mlen\u001B[39m(nodes_to) \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mlen\u001B[39m(nodes_from)) \u001B[38;5;28;01mif\u001B[39;00m log \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28miter\u001B[39m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m f,t \u001B[38;5;129;01min\u001B[39;00m generator:\n\u001B[0;32m----> 9\u001B[0m     p \u001B[38;5;241m=\u001B[39m \u001B[43mnx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msingle_source_dijkstra\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgraph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mlength\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     10\u001B[0m     \u001B[38;5;28mcls\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mdict\u001B[39m\u001B[38;5;241m.\u001B[39mfromkeys([\u001B[38;5;28mint\u001B[39m(graph\u001B[38;5;241m.\u001B[39mnodes()[u][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcluster\u001B[39m\u001B[38;5;124m'\u001B[39m]) \u001B[38;5;28;01mfor\u001B[39;00m u \u001B[38;5;129;01min\u001B[39;00m p[\u001B[38;5;241m1\u001B[39m]]))\n\u001B[1;32m     11\u001B[0m     \u001B[38;5;28mcls\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mtuple\u001B[39m(\u001B[38;5;28mcls\u001B[39m)\n",
      "File \u001B[0;32m<class 'networkx.utils.decorators.argmap'> compilation 69:3\u001B[0m, in \u001B[0;36margmap_single_source_dijkstra_66\u001B[0;34m(G, source, target, cutoff, weight, backend, **backend_kwargs)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mbz2\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mcollections\u001B[39;00m\n\u001B[0;32m----> 3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mgzip\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01minspect\u001B[39;00m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mitertools\u001B[39;00m\n",
      "File \u001B[0;32m~/graph_clustering/.venv/lib/python3.10/site-packages/networkx/utils/backends.py:633\u001B[0m, in \u001B[0;36m_dispatchable.__call__\u001B[0;34m(self, backend, *args, **kwargs)\u001B[0m\n\u001B[1;32m    628\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Returns the result of the original function, or the backend function if\u001B[39;00m\n\u001B[1;32m    629\u001B[0m \u001B[38;5;124;03mthe backend is specified and that backend implements `func`.\"\"\"\u001B[39;00m\n\u001B[1;32m    631\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m backends:\n\u001B[1;32m    632\u001B[0m     \u001B[38;5;66;03m# Fast path if no backends are installed\u001B[39;00m\n\u001B[0;32m--> 633\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43morig_func\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    635\u001B[0m \u001B[38;5;66;03m# Use `backend_name` in this function instead of `backend`\u001B[39;00m\n\u001B[1;32m    636\u001B[0m backend_name \u001B[38;5;241m=\u001B[39m backend\n",
      "File \u001B[0;32m~/graph_clustering/.venv/lib/python3.10/site-packages/networkx/algorithms/shortest_paths/weighted.py:489\u001B[0m, in \u001B[0;36msingle_source_dijkstra\u001B[0;34m(G, source, target, cutoff, weight)\u001B[0m\n\u001B[1;32m    392\u001B[0m \u001B[38;5;129m@nx\u001B[39m\u001B[38;5;241m.\u001B[39m_dispatchable(edge_attrs\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mweight\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    393\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21msingle_source_dijkstra\u001B[39m(G, source, target\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, cutoff\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, weight\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mweight\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m    394\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Find shortest weighted paths and lengths from a source node.\u001B[39;00m\n\u001B[1;32m    395\u001B[0m \n\u001B[1;32m    396\u001B[0m \u001B[38;5;124;03m    Compute the shortest path length between source and all other\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    487\u001B[0m \u001B[38;5;124;03m    single_source_bellman_ford\u001B[39;00m\n\u001B[1;32m    488\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 489\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmulti_source_dijkstra\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    490\u001B[0m \u001B[43m        \u001B[49m\u001B[43mG\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[43msource\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcutoff\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcutoff\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtarget\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mweight\u001B[49m\n\u001B[1;32m    491\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m<class 'networkx.utils.decorators.argmap'> compilation 73:3\u001B[0m, in \u001B[0;36margmap_multi_source_dijkstra_70\u001B[0;34m(G, sources, target, cutoff, weight, backend, **backend_kwargs)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mbz2\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mcollections\u001B[39;00m\n\u001B[0;32m----> 3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mgzip\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01minspect\u001B[39;00m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mitertools\u001B[39;00m\n",
      "File \u001B[0;32m~/graph_clustering/.venv/lib/python3.10/site-packages/networkx/utils/backends.py:633\u001B[0m, in \u001B[0;36m_dispatchable.__call__\u001B[0;34m(self, backend, *args, **kwargs)\u001B[0m\n\u001B[1;32m    628\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Returns the result of the original function, or the backend function if\u001B[39;00m\n\u001B[1;32m    629\u001B[0m \u001B[38;5;124;03mthe backend is specified and that backend implements `func`.\"\"\"\u001B[39;00m\n\u001B[1;32m    631\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m backends:\n\u001B[1;32m    632\u001B[0m     \u001B[38;5;66;03m# Fast path if no backends are installed\u001B[39;00m\n\u001B[0;32m--> 633\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43morig_func\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    635\u001B[0m \u001B[38;5;66;03m# Use `backend_name` in this function instead of `backend`\u001B[39;00m\n\u001B[1;32m    636\u001B[0m backend_name \u001B[38;5;241m=\u001B[39m backend\n",
      "File \u001B[0;32m~/graph_clustering/.venv/lib/python3.10/site-packages/networkx/algorithms/shortest_paths/weighted.py:759\u001B[0m, in \u001B[0;36mmulti_source_dijkstra\u001B[0;34m(G, sources, target, cutoff, weight)\u001B[0m\n\u001B[1;32m    757\u001B[0m weight \u001B[38;5;241m=\u001B[39m _weight_function(G, weight)\n\u001B[1;32m    758\u001B[0m paths \u001B[38;5;241m=\u001B[39m {source: [source] \u001B[38;5;28;01mfor\u001B[39;00m source \u001B[38;5;129;01min\u001B[39;00m sources}  \u001B[38;5;66;03m# dictionary of paths\u001B[39;00m\n\u001B[0;32m--> 759\u001B[0m dist \u001B[38;5;241m=\u001B[39m \u001B[43m_dijkstra_multisource\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    760\u001B[0m \u001B[43m    \u001B[49m\u001B[43mG\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msources\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpaths\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpaths\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcutoff\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcutoff\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtarget\u001B[49m\n\u001B[1;32m    761\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    762\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m target \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    763\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m (dist, paths)\n",
      "File \u001B[0;32m~/graph_clustering/.venv/lib/python3.10/site-packages/networkx/algorithms/shortest_paths/weighted.py:852\u001B[0m, in \u001B[0;36m_dijkstra_multisource\u001B[0;34m(G, sources, weight, pred, paths, cutoff, target)\u001B[0m\n\u001B[1;32m    850\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m fringe:\n\u001B[1;32m    851\u001B[0m     (d, _, v) \u001B[38;5;241m=\u001B[39m pop(fringe)\n\u001B[0;32m--> 852\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m v \u001B[38;5;129;01min\u001B[39;00m dist:\n\u001B[1;32m    853\u001B[0m         \u001B[38;5;28;01mcontinue\u001B[39;00m  \u001B[38;5;66;03m# already searched this node.\u001B[39;00m\n\u001B[1;32m    854\u001B[0m     dist[v] \u001B[38;5;241m=\u001B[39m d\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "l = range(len(cms))\n",
    "iter = itertools.product(l,l)\n",
    "one = 0\n",
    "other = 0\n",
    "for n,(i,j) in tqdm(enumerate(iter), total = len(cms)**2):\n",
    "    stat = get_statistic_per_point(g, i, j, cls2hubs, False)\n",
    "    total = sum([x[1] for x in stat.items()])\n",
    "    stat = list(stat.items())\n",
    "    stat.sort(key=lambda x:-x[1])\n",
    "    stat=dict(stat)\n",
    "    if (len(stat)) == 1:\n",
    "        one+=1\n",
    "    else:\n",
    "        other+=1\n",
    "    if n > 200:\n",
    "        break\n",
    "    # print('stat:')\n",
    "    # for u,d in stat.items():\n",
    "    #     print(f'{d/total:.2f}')\n",
    "print(one, other)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-16T09:31:27.280790Z",
     "start_time": "2024-10-16T09:28:35.724928Z"
    }
   },
   "id": "f86331bf298d6faf",
   "execution_count": 72
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 15\n"
     ]
    }
   ],
   "source": [
    "print(one, other)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-16T09:31:29.895632Z",
     "start_time": "2024-10-16T09:31:29.889847Z"
    }
   },
   "id": "34a1cebee8acf432",
   "execution_count": 73
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": "build ad_matrix, work:0:   0%|          | 0/209 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5592e4834401460e9c745a16a6f39465"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": "build ad_matrix, work:1:   0%|          | 0/209 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5a8b6afc2f604fb4b210def99767ecaa"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start: 2\n"
     ]
    },
    {
     "data": {
      "text/plain": "build ad_matrix, work:2:   0%|          | 0/208 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7ea6a5be5f8f45f7880d4792578294e3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start: 3\n"
     ]
    },
    {
     "data": {
      "text/plain": "build ad_matrix, work:3:   0%|          | 0/208 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "124fe92b62b049c28bce3dc10cc7ab63"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[19], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m ad_mat \u001B[38;5;241m=\u001B[39m \u001B[43mget_ad_matrix\u001B[49m\u001B[43m(\u001B[49m\u001B[43mg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcms\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcls2hubs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcls2n\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mWORKERS\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m4\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[18], line 74\u001B[0m, in \u001B[0;36mget_ad_matrix\u001B[0;34m(graph, communities, cls2hubs, cls2n, WORKERS)\u001B[0m\n\u001B[1;32m     66\u001B[0m data \u001B[38;5;241m=\u001B[39m [{\n\u001B[1;32m     67\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mg\u001B[39m\u001B[38;5;124m'\u001B[39m: graph,\n\u001B[1;32m     68\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpoints\u001B[39m\u001B[38;5;124m'\u001B[39m: [i \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(worker, \u001B[38;5;28mlen\u001B[39m(communities), WORKERS)],\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     71\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mworker\u001B[39m\u001B[38;5;124m'\u001B[39m: worker\n\u001B[1;32m     72\u001B[0m } \u001B[38;5;28;01mfor\u001B[39;00m worker \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(WORKERS)]\n\u001B[1;32m     73\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m Pool(WORKERS) \u001B[38;5;28;01mas\u001B[39;00m p:\n\u001B[0;32m---> 74\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[43mp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdo_ad_mat\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     75\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m r \u001B[38;5;129;01min\u001B[39;00m res:\n\u001B[1;32m     76\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m r:\n",
      "File \u001B[0;32m/usr/lib/python3.10/multiprocessing/pool.py:367\u001B[0m, in \u001B[0;36mPool.map\u001B[0;34m(self, func, iterable, chunksize)\u001B[0m\n\u001B[1;32m    362\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mmap\u001B[39m(\u001B[38;5;28mself\u001B[39m, func, iterable, chunksize\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m    363\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m'''\u001B[39;00m\n\u001B[1;32m    364\u001B[0m \u001B[38;5;124;03m    Apply `func` to each element in `iterable`, collecting the results\u001B[39;00m\n\u001B[1;32m    365\u001B[0m \u001B[38;5;124;03m    in a list that is returned.\u001B[39;00m\n\u001B[1;32m    366\u001B[0m \u001B[38;5;124;03m    '''\u001B[39;00m\n\u001B[0;32m--> 367\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_map_async\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43miterable\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmapstar\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mchunksize\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/lib/python3.10/multiprocessing/pool.py:768\u001B[0m, in \u001B[0;36mApplyResult.get\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    767\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget\u001B[39m(\u001B[38;5;28mself\u001B[39m, timeout\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m--> 768\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    769\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mready():\n\u001B[1;32m    770\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTimeoutError\u001B[39;00m\n",
      "File \u001B[0;32m/usr/lib/python3.10/multiprocessing/pool.py:765\u001B[0m, in \u001B[0;36mApplyResult.wait\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    764\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwait\u001B[39m(\u001B[38;5;28mself\u001B[39m, timeout\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m--> 765\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_event\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/lib/python3.10/threading.py:607\u001B[0m, in \u001B[0;36mEvent.wait\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    605\u001B[0m signaled \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_flag\n\u001B[1;32m    606\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m signaled:\n\u001B[0;32m--> 607\u001B[0m     signaled \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_cond\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    608\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m signaled\n",
      "File \u001B[0;32m/usr/lib/python3.10/threading.py:320\u001B[0m, in \u001B[0;36mCondition.wait\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    318\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:    \u001B[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001B[39;00m\n\u001B[1;32m    319\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 320\u001B[0m         \u001B[43mwaiter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43macquire\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    321\u001B[0m         gotit \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    322\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "ad_mat = get_ad_matrix(g, cms, cls2hubs, cls2n, WORKERS=4)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-16T08:42:10.403202Z",
     "start_time": "2024-10-16T08:42:04.900979Z"
    }
   },
   "id": "e2bc4ee81e611853",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-16T08:42:20.056376Z",
     "start_time": "2024-10-16T08:42:20.053307Z"
    }
   },
   "id": "109549702ee04b9d",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "find centroids:   0%|          | 0/834 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4de4c750878c451bbc2f86aef6ecd4c8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "find edges:   0%|          | 0/834 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d497571ebfb549468fdd29262557c4d8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "g1, cls2c = build_center_graph(g, cms, ad_mat, cls2n)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-16T08:42:43.587971Z",
     "start_time": "2024-10-16T08:42:21.613790Z"
    }
   },
   "id": "718024858ba64653",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def build_geodetic(g_centers, ad_mat):\n",
    "    paths = dict(tqdm(nx.all_pairs_dijkstra_path(g_centers, weight='length'), total=(len(g_centers.nodes()))))\n",
    "    paths_len = dict(tqdm(nx.all_pairs_dijkstra_path_length(g_centers, weight='length'), total=(len(g_centers.nodes()))))\n",
    "    nodes = list(g_centers.nodes())\n",
    "    paths_t = [(nodes[i],nodes[j],paths_len[nodes[i]][nodes[j]],paths[nodes[i]][nodes[j]]) for i in range(len(nodes)) for j in range(i+1, len(nodes))]\n",
    "    del paths_len\n",
    "    del paths\n",
    "    paths_t.sort(key=lambda x:-len(x[3]))\n",
    "    data_graph = {u : {} for u in nodes }\n",
    "    for u in nodes:\n",
    "        for v in nodes:\n",
    "            data_graph[u][v]=None\n",
    "            \n",
    "    for u,v,length,path in tqdm(paths_t):\n",
    "        gg = None\n",
    "        num_nodes = 0\n",
    "        for i in range(len(path) - 1):\n",
    "            c1 = path[i]\n",
    "            c2 = path[i+1]\n",
    "            for cc in ad_mat[c1][c2]:\n",
    "                num_nodes += len(cms[cc])\n",
    "        cls = set()\n",
    "        for i in range(len(path) - 1):\n",
    "            u = path[i]\n",
    "            v = path[i + 1]\n",
    "            cu = g.nodes()[cls2c[u]]['cluster']\n",
    "            cv = g.nodes()[cls2c[v]]['cluster']\n",
    "            for c in ad_mat[cu][cv]:\n",
    "                cls.add(c)\n",
    "            cls.add(cu)\n",
    "            cls.add(cv)\n",
    "        new_num_nodes = sum([len(cms[c]) for c in cls])\n",
    "        for p1 in path:\n",
    "            for p2 in path:\n",
    "                gg0 = data_graph[p1][p2]\n",
    "                if gg0 is None:\n",
    "                    if gg is None:\n",
    "                        gg = extract_cluster_list_subgraph(g, path, cms)\n",
    "                    data_graph[p1][p2] = gg\n",
    "                    data_graph[p2][p1] = gg\n",
    "                    \n",
    "                    # data_graph[p1][p2] = cls\n",
    "                    # data_graph[p2][p1] = cls\n",
    "                    continue\n",
    "                # если новый кусок существенно меньше старого\n",
    "                # if num_nodes/10 > new_num_nodes:\n",
    "                #     if gg is None:\n",
    "                #         gg = extract_cluster_list_subgraph(g, path, cms)\n",
    "                #     data_graph[p1][p2] = gg\n",
    "                #     data_graph[p2][p1] = gg\n",
    "    return data_graph"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-16T09:02:26.041431Z",
     "start_time": "2024-10-16T09:02:26.025478Z"
    }
   },
   "id": "f208a248aac0715",
   "execution_count": 53
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# del data_graph"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-16T09:02:28.548743Z",
     "start_time": "2024-10-16T09:02:28.299503Z"
    }
   },
   "id": "7bd70c60d44e78d8",
   "execution_count": 54
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/834 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5ab97b3778b14bcdaf34af0679aa0998"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/834 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9c5b7c9a07274d1a819b722121d5346c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/347361 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "af6f246825604b0e9d9e8f10cd81042d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_graph = build_geodetic(g1,ad_mat)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-16T09:03:14.189917Z",
     "start_time": "2024-10-16T09:02:30.085061Z"
    }
   },
   "id": "8148498b6b4288c6",
   "execution_count": 55
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# find path between two points\n",
    "def find_path_length_h(\n",
    "        g0: nx.Graph,\n",
    "        g1: nx.Graph,\n",
    "        adjacency: dict[int, dict[int:set[int]]],\n",
    "        cms: list[set[int]] | tuple[set[int]],\n",
    "        cls2c: dict[int:int],\n",
    "        from_node: int,\n",
    "        to_node: int,\n",
    "        cls2n: dict[int, set[int]]) -> float:\n",
    "    from_cluster = g0.nodes()[from_node]['cluster']\n",
    "    to_cluster = g0.nodes()[to_node]['cluster']\n",
    "\n",
    "    cls = {to_cluster, from_cluster}\n",
    "\n",
    "    def h(a, b):\n",
    "        da = g0.nodes()[cls2c[a]]\n",
    "        db = g0.nodes()[to_node]\n",
    "        return ((da['x'] - db['x']) ** 2 + (da['y'] - db['y']) ** 2) ** 0.5 / 360 * 2 * np.pi * 6371.01 * 1000 * 0.56\n",
    "\n",
    "    # path = nx.single_source_dijkstra(g1, from_cluster, to_cluster, weight='length')[1]\n",
    "    path = nx.astar_path(g1, from_cluster, to_cluster, weight='length', heuristic=h)\n",
    "    for i in range(len(path) - 1):\n",
    "        u = path[i]\n",
    "        v = path[i + 1]\n",
    "        cu = g0.nodes()[cls2c[u]]['cluster']\n",
    "        cv = g0.nodes()[cls2c[v]]['cluster']\n",
    "        # for c in adjacency[cu][cv]:\n",
    "        #     cls.add(c)\n",
    "        cls.add(cu)\n",
    "        cls.add(cv)\n",
    "\n",
    "    # for c1 in cls2n[to_cluster].union({to_cluster}):\n",
    "    #     for c2 in cls2n[from_cluster].union({from_cluster}):\n",
    "    #         path = nx.astar_path(g1, c1, c2, h, weight='length')\n",
    "    #         for i in range(len(path) - 1):\n",
    "    #             u = path[i]\n",
    "    #             v = path[i + 1]\n",
    "    #             cu = g0.nodes()[cls2c[u]]['cluster']\n",
    "    #             cv = g0.nodes()[cls2c[v]]['cluster']\n",
    "    #             # for c in adjacency[cu][cv]:\n",
    "    #             #     cls.add(c)\n",
    "    #             cls.add(cu)\n",
    "    #             cls.add(cv)\n",
    "    def h(a, b):\n",
    "        da = g0.nodes()[a]\n",
    "        db = g0.nodes()[b]\n",
    "        return ((da['x'] - db['x']) ** 2 + (da['y'] - db['y']) ** 2) ** 0.5 / 360 * 2 * np.pi * 6371.01 * 1000 * 0.56\n",
    "\n",
    "    g = extract_cluster_list_subgraph(g0, cls, cms)\n",
    "    # return nx.astar_path_length(g, from_node, to_node, weight='length', heuristic=h), []\n",
    "    return nx.single_source_dijkstra(g, from_node, to_node, weight='length')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-16T08:42:58.363176Z",
     "start_time": "2024-10-16T08:42:58.346437Z"
    }
   },
   "id": "4b342577bf04575e",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# find path between two points with few layer \n",
    "# метод не показал хороших реальтатов, ошибка растет примерно в 5 раз, ускорение не меняется\n",
    "def find_path_length_h_few_layer(\n",
    "        g0: nx.Graph,\n",
    "        g1: nx.Graph,\n",
    "        g2: nx.Graph,\n",
    "        cms: list[set[int]] | tuple[set[int]],\n",
    "        cms_1: list[set[int]] | tuple[set[int]],\n",
    "        cls2c: dict[int:int],\n",
    "        cls2c_1: dict[int:int],\n",
    "        from_node: int,\n",
    "        to_node: int,\n",
    "        ) -> float:\n",
    "    \n",
    "    from_cluster = g0.nodes()[from_node]['cluster']\n",
    "    to_cluster = g0.nodes()[to_node]['cluster']\n",
    "\n",
    "    from_cluster1 = g1.nodes()[from_cluster]['cluster']\n",
    "    to_cluster1 = g1.nodes()[to_cluster]['cluster']\n",
    "\n",
    "    cls = {to_cluster1, from_cluster1}\n",
    "    path = nx.single_source_dijkstra(g2, from_cluster1, to_cluster1, weight='length')[1]\n",
    "    \n",
    "    for i in range(len(path) - 1):\n",
    "        u = path[i]\n",
    "        v = path[i + 1]\n",
    "        cu = g1.nodes()[cls2c_1[u]]['cluster']\n",
    "        cv = g1.nodes()[cls2c_1[v]]['cluster']\n",
    "        cls.add(cu)\n",
    "        cls.add(cv)\n",
    "    g = extract_cluster_list_subgraph(g1, cls, cms_1)\n",
    "    \n",
    "    path = nx.single_source_dijkstra(g, from_cluster, to_cluster, weight='length')[1]\n",
    "    cls = {to_cluster, from_cluster}\n",
    "    for i in range(len(path) - 1):\n",
    "        u = path[i]\n",
    "        v = path[i + 1]\n",
    "        cu = g0.nodes()[cls2c[u]]['cluster']\n",
    "        cv = g0.nodes()[cls2c[v]]['cluster']\n",
    "        cls.add(cu)\n",
    "        cls.add(cv)\n",
    "\n",
    "    g = extract_cluster_list_subgraph(g0, cls, cms)\n",
    "    return nx.single_source_dijkstra(g, from_node, to_node, weight='length')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-16T08:42:59.815989Z",
     "start_time": "2024-10-16T08:42:59.804411Z"
    }
   },
   "id": "b5cc5db55eddc075",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# find path between two points\n",
    "def find_path_length_h_with_graphs(\n",
    "        g0: nx.Graph,\n",
    "        from_node: int,\n",
    "        to_node: int) -> float:\n",
    "    from_cluster = g0.nodes()[from_node]['cluster']\n",
    "    to_cluster = g0.nodes()[to_node]['cluster']\n",
    "    \n",
    "    def h(a, b):\n",
    "        da = g0.nodes()[a]\n",
    "        db = g0.nodes()[b]\n",
    "        return ((da['x'] - db['x']) ** 2 + (da['y'] - db ['y']) ** 2) ** 0.5 / 360 * 2 * np.pi * 6371.01 * 1000 * 0.56\n",
    "\n",
    "    # return nx.astar_path_length(data_graph[from_cluster][to_cluster], from_node, to_node, weight='length', heuristic=h), []\n",
    "    \n",
    "    # g = extract_cluster_list_subgraph(g0,data_graph[from_cluster][to_cluster], cms)\n",
    "    g = data_graph[from_cluster][to_cluster]\n",
    "    return nx.single_source_dijkstra(g, from_node, to_node, weight='length')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-16T09:03:56.808100Z",
     "start_time": "2024-10-16T09:03:56.803303Z"
    }
   },
   "id": "3ad500622fb7b60e",
   "execution_count": 57
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# пример второго слоя в кластеризации\n",
    "# from sklearn.cluster import KMeans, DBSCAN, HDBSCAN, BisectingKMeans\n",
    "# def f(a,b):\n",
    "#     u = int(a[2])\n",
    "#     v = int(b[2])\n",
    "#     if (u,v) in g1.edges() or (v,u) in g1.edges():\n",
    "#         return g1.edges()[(u,v)]['length']\n",
    "#     return float('inf')\n",
    "#     # return nx.single_source_dijkstra(g, u,v,weight='length')[0]\n",
    "# scan = HDBSCAN(metric=f, min_samples=1)\n",
    "# x = np.array([[d['x'], d['y'], u] for u, d in g1.nodes(data=True)])\n",
    "# y = scan.fit_predict(x)\n",
    "# communities = {}\n",
    "# for i, u in enumerate(g1.nodes):\n",
    "#     cls = y[i]\n",
    "#     if cls not in communities:\n",
    "#         communities[cls] = set()\n",
    "#     communities[cls].add(u)\n",
    "# communities = [communities[cls] for cls in communities]\n",
    "# cls = []\n",
    "# for i, c in enumerate(communities):\n",
    "#     for n in nx.connected_components(g1.subgraph(c)):\n",
    "#         cls.append(n)\n",
    "# for i, ids in enumerate(cls):\n",
    "#     for j in ids:\n",
    "#         g1.nodes()[j]['cluster'] = i\n",
    "# cms_1 = cls\n",
    "# len(cms_1)\n",
    "# cls2n_1 = get_cls2n(g1)\n",
    "# cls2hubs_1 = get_cls2hubs(g1)\n",
    "# ad_mat_1 = get_ad_matrix(g1, cms_1, cls2hubs_1, cls2n_1, WORKERS=20)\n",
    "# g2, cls2c_1 = build_center_graph(g1, cms_1, ad_mat_1, cls2n_1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "24ae55850197968",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "generate points:   0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c7e09025fcab4e3baed9b3d8694163be"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_node_for_initial_graph_v2(graph: nx.Graph):\n",
    "    nodes = list(graph.nodes())\n",
    "    f, t = random.choice(nodes), random.choice(nodes)\n",
    "    while f == t:\n",
    "        f, t = random.choice(nodes), random.choice(nodes)\n",
    "    return f, t\n",
    "\n",
    "# if os.path.exists('../data/points.pkl'):\n",
    "#     with open('../data/points.pkl', 'rb') as fp:\n",
    "#         points = pickle.load(fp)\n",
    "#         fp.close()\n",
    "# else:\n",
    "points = [get_node_for_initial_graph_v2(g) for _ in trange(1000, desc='generate points')]\n",
    "# with open('../data/points.pkl', 'wb') as fp:\n",
    "#     pickle.dump(points, fp)\n",
    "#     fp.close()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-16T08:43:08.887746Z",
     "start_time": "2024-10-16T08:43:08.566055Z"
    }
   },
   "id": "950e8ced345d955d",
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "source": [
    "check a-star\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c3d45ffe68be085"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "h_coef = 1\n",
    "def h_func(a, b):\n",
    "    da = g.nodes()[a]\n",
    "    db = g.nodes()[b]\n",
    "    return ((da['x'] - db['x']) ** 2 + (da['y'] - db['y']) ** 2) ** 0.5 / 360 * 2 * np.pi * 6371.01 * 1000\n",
    "\n",
    "for e in g.edges():\n",
    "    u,v = e\n",
    "    du,dv=g.nodes()[u], g.nodes()[v]\n",
    "    w = g.edges()[e]['length']\n",
    "    h = h_func(u,v)\n",
    "    h_coef = min(h_coef, w/h)\n",
    "h_coef"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9b72452925fd24cc",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "h_coef_upper = 1\n",
    "def h_func(a, b):\n",
    "    da = g1.nodes()[a]\n",
    "    db = g1.nodes()[b]\n",
    "    return ((da['x'] - db['x']) ** 2 + (da['y'] - db['y']) ** 2) ** 0.5 / 360 * 2 * np.pi * 6371.01 * 1000\n",
    "\n",
    "for e in g1.edges():\n",
    "    u,v = e\n",
    "    du,dv=g1.nodes()[u], g1.nodes()[v]\n",
    "    w = g1.edges()[e]['length']\n",
    "    h = h_func(u,v)\n",
    "    h_coef_upper = min(h_coef_upper, w/h)\n",
    "h_coef_upper"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e4a8360cd714c46c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "def h(a, b):\n",
    "    da = g.nodes()[a]\n",
    "    db = g.nodes()[b]\n",
    "    return ((da['x'] - db['x']) ** 2 + (da['y'] - db['y']) ** 2) ** 0.5 / 360 * 2 * np.pi * 6371.01 * 1000 *h_coef\n",
    "\n",
    "def do_calc(data):\n",
    "    pps, i = data\n",
    "\n",
    "    stat = {}\n",
    "    stat['l'] = []\n",
    "    stat['h_l'] = []\n",
    "    stat['time_l'] = []\n",
    "    stat['time_h'] = []\n",
    "\n",
    "    stat['delta'] = []\n",
    "    sleep(i/10)\n",
    "    print('start', i)\n",
    "    for p1, p2 in tqdm(pps, desc='find paths', position=i):\n",
    "        if (p1, p2) in stat:\n",
    "            continue\n",
    "        num_iter = 2\n",
    "        length, p = None, None\n",
    "        start = time.time()\n",
    "        for _ in range(num_iter):\n",
    "            length, p = nx.single_source_dijkstra(g, p1, p2, weight='length')\n",
    "        time_l = time.time() - start\n",
    "        h_l, h_p = None, None\n",
    "        start = time.time()\n",
    "        for _ in range(num_iter):\n",
    "            h_l = nx.astar_path_length(g,  p1, p2, h,weight='length')\n",
    "        time_h = time.time() - start\n",
    "        delta = (h_l - length) / length * 100\n",
    "        stat['l'].append(length)\n",
    "        stat['h_l'].append(h_l)\n",
    "        stat['delta'].append(delta)\n",
    "        stat['time_l'].append(time_l)\n",
    "        stat['time_h'].append(time_h)\n",
    "\n",
    "    return stat\n",
    "astar = True\n",
    "if astar:\n",
    "    WORKER = 4\n",
    "    data = [([p for p in points[i::WORKER]], i) for i in range(WORKER)]\n",
    "    with Pool(WORKER) as p:\n",
    "        res = p.map(do_calc, data)\n",
    "    stat = {}\n",
    "    for l in res:\n",
    "        for d in l:\n",
    "            if d not in stat:\n",
    "                stat[d] = []\n",
    "            stat[d].extend(l[d])\n",
    "    print('err_mean:', np.mean(stat['delta']))\n",
    "    print('err_min:', np.min(stat['delta']))\n",
    "    print('err_max:', np.max(stat['delta']))\n",
    "    print(np.mean(np.array(stat['time_l']) / np.array(stat['time_h'])))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "794616aaec2f6de5",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start 0\n"
     ]
    },
    {
     "data": {
      "text/plain": "find paths:   0%|          | 0/250 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "73fb3357aaf044a48aff74b4e67536c8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start 1\n"
     ]
    },
    {
     "data": {
      "text/plain": "find paths:   0%|          | 0/250 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "469a4817a82649c68eae310545528c78"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start 2\n"
     ]
    },
    {
     "data": {
      "text/plain": "find paths:   0%|          | 0/250 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6359e687d59049b9ab8e162d17565287"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start 3\n"
     ]
    },
    {
     "data": {
      "text/plain": "find paths:   0%|          | 0/250 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c49c1db93acd40679e89c432554185f5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "err_mean: 21.617162731070515\n",
      "err_min: 0.0\n",
      "err_max: 182.73737134999243\n",
      "26.148983549161386\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "def do_calc(data):\n",
    "    pps, i = data\n",
    "\n",
    "    stat = {}\n",
    "    stat['l'] = []\n",
    "    stat['h_l'] = []\n",
    "    stat['p'] = []\n",
    "    stat['h_p'] = []\n",
    "    stat['time_l'] = []\n",
    "    stat['time_h'] = []\n",
    "\n",
    "    stat['delta'] = []\n",
    "    sleep(i/10)\n",
    "    print('start', i)\n",
    "    for p1, p2 in tqdm(pps, desc='find paths', position=i):\n",
    "        if (p1, p2) in stat:\n",
    "            continue\n",
    "        num_iter = 2\n",
    "        l, p = None, None\n",
    "        start = time.time()\n",
    "        for i in range(num_iter):\n",
    "            l, p = nx.single_source_dijkstra(g, p1, p2, weight='length')\n",
    "        time_l = time.time() - start\n",
    "        h_l, h_p = None, None\n",
    "        start = time.time()\n",
    "        for _ in range(num_iter):\n",
    "            # h_l, h_p  = find_path_length_k_paths(g, g1, ad_mat,cms, cls2c, p1, p2, cls2n)\n",
    "            # h_l, h_p = find_path_length_h(g, g1, ad_mat,cms, cls2c, p1, p2, cls2n)\n",
    "            # h_l, h_p = find_path_length_h(g, p1, p2)\n",
    "            h_l, h_p = find_path_length_h_with_graphs(g,p1, p2)\n",
    "        \n",
    "        time_h = time.time() - start\n",
    "        \n",
    "        delta = (h_l - l) / l * 100\n",
    "        stat['l'].append(l)\n",
    "        stat['h_l'].append(h_l)\n",
    "        stat['p'].append(p)\n",
    "        stat['h_p'].append(h_p)\n",
    "        stat['delta'].append(delta)\n",
    "        stat['time_l'].append(time_l)\n",
    "        stat['time_h'].append(time_h)\n",
    "\n",
    "    return stat\n",
    "\n",
    "WORKER = 4\n",
    "data = [([p for p in points[i::WORKER]], i) for i in range(WORKER)]\n",
    "# do_calc(data[0])\n",
    "with Pool(WORKER) as p:\n",
    "    res = p.map(do_calc, data)\n",
    "stat = {}\n",
    "for l in res:\n",
    "    for d in l:\n",
    "        if d not in stat:\n",
    "            stat[d] = []\n",
    "        stat[d].extend(l[d])\n",
    "\n",
    "print('err_mean:', np.mean(stat['delta']))\n",
    "print('err_min:', np.min(stat['delta']))\n",
    "print('err_max:', np.max(stat['delta']))\n",
    "print(np.mean(np.array(stat['time_l']) / np.array(stat['time_h'])))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-16T09:04:57.710242Z",
     "start_time": "2024-10-16T09:04:00.167906Z"
    }
   },
   "id": "d7674e5d2cbc4bb2",
   "execution_count": 58
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "data = stat['delta']\n",
    "data = np.array(data)\n",
    "# data = data[data<10]\n",
    "x = data\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 4))\n",
    "ax.set(xlabel='err, %', ylabel='count')\n",
    "# ax[0].hist(x,bins=40, density=True, color='grey')\n",
    "\n",
    "hist, bins = np.histogram(x, bins=100)\n",
    "ax.bar(bins[:-1], hist.astype(np.float32) / hist.sum(), width=(bins[1] - bins[0]))\n",
    "# ax.set_   \n",
    "# print(bins)\n",
    "# ax[0].set_title('normed=True')\n",
    "ax.set_title('hist = hist / hist.sum()')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f3741ad6279790a5",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "df = pd.DataFrame.from_dict(stat)\n",
    "fig, axs = plt.subplots(1, 1)\n",
    "fig.set_figwidth(20)\n",
    "fig.set_figheight(20)\n",
    "\n",
    "df.hist(column=['delta'], density=1, bins=10, ax=axs, xlabelsize=20, ylabelsize=20)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fbaff5b7821ee461",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "24171ff672d5637d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "f = df.get(['delta', 'l', 'h_l'])\n",
    "# plt.scatter(f['l'], f['delta'])\n",
    "# plt.scatter(f['h_l'], f['delta'])\n",
    "\n",
    "x = np.linspace(min(f['l']), max(f['l']), 100)\n",
    "plt.plot(x, x, c='red')\n",
    "plt.scatter(f['l'], f['h_l'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b29c28d558feb5da",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "delta = f['h_l'] - f['l']\n",
    "print(f\"\"\"\n",
    "max: {np.max(delta):.2f}\n",
    "mean: {np.mean(delta):.2f} +- {np.std(delta):.2f}\n",
    "\"\"\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "84837cdae3f447b7",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "slope, intercept, r_value, p_value, std_err = scipy.stats.linregress(f['l'], f['h_l'])\n",
    "# coefficient_of_dermination = r2_score(f['l'], f['h_l'])\n",
    "print(f\"\"\"\n",
    "r: {r_value}\n",
    "p: {p_value}\n",
    "\"\"\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "40d60f31ae922be5",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "\n",
    "\n",
    "def line(x, a, b):\n",
    "    return a * x + b\n",
    "\n",
    "\n",
    "popt = curve_fit(line, f['l'], f['h_l'])\n",
    "print(f\"\"\"\n",
    "a: {popt[0][0]:.4f} +- {np.sqrt(popt[1][0, 0]):.8f}\n",
    "b: {popt[0][1]:.4f} +- {np.sqrt(popt[1][1, 1]):.8f}\n",
    "\"\"\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9cd84b69640e94ca",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "b94e38be2b00e026",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def get_color_list(l: int):\n",
    "    cmap = plt.get_cmap('plasma')\n",
    "    colors = [cmap(i / l) for i in range(l)]\n",
    "    hex_colors = ['#' + ''.join([f'{int(c * 255):02x}' for c in color[:3]]) \\\n",
    "                  for color in colors]\n",
    "    return hex_colors\n",
    "\n",
    "\n",
    "def draw_on_map(_g: nx.Graph,\n",
    "                communities: tuple = None,\n",
    "                m: folium.Map = None,\n",
    "                node_colors: list | str = None,\n",
    "                edge_colors: str = 'black') -> folium.Map:\n",
    "    if communities is None:\n",
    "        communities = [{u} for u in _g.nodes()]\n",
    "    if node_colors is None:\n",
    "        node_colors = get_color_list(len(communities))\n",
    "\n",
    "    if m is None:\n",
    "        for u, d in _g.nodes(data=True):\n",
    "            u_x, u_y = d['x'], d['y']\n",
    "            break\n",
    "        m = folium.Map(location=[u_y, u_x], zoom_start=10)  # Координаты города\n",
    "    for i, community in enumerate(communities):\n",
    "            \n",
    "        for node in community:\n",
    "            if node not in _g.nodes():\n",
    "                continue\n",
    "            node_data = _g.nodes[node]\n",
    "            popup_text = f\"Кластер: {i}, \\n\" + f\"номер: {node}\"\n",
    "            folium.CircleMarker(\n",
    "                location=(node_data['y'], node_data['x']),\n",
    "                radius=4,\n",
    "                color=node_colors[i] if isinstance(node_colors, list) else node_colors,\n",
    "                fill=True,\n",
    "                fill_color=node_colors[i] if isinstance(node_colors, list) is list else node_colors,\n",
    "                fill_opacity=0.7,\n",
    "                popup=popup_text\n",
    "            ).add_to(m)\n",
    "    if not (edge_colors is None):\n",
    "        for u, v, data in _g.edges(data=True):\n",
    "            u_x, u_y = _g.nodes()[u]['x'], _g.nodes()[u]['y']\n",
    "            v_x, v_y = _g.nodes()[v]['x'], _g.nodes()[v]['y']\n",
    "            folium.PolyLine([(u_y, u_x), (v_y, v_x)], color=edge_colors, weight=1).add_to(m)\n",
    "    return m"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3a66e853cda3113e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# рисовалка для osm\n",
    "# m = draw_on_map(g, node_colors='red')\n",
    "# m.save('msk_without_2_deg.html')\n",
    "# m.show_in_browser()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e2053e67c42b098b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# рисует топ по ошибкам\n",
    "sorted = np.argsort(stat['delta'])\n",
    "index = -1\n",
    "while stat['delta'][sorted[index]] > 5:\n",
    "    print(stat['delta'][sorted[index]])\n",
    "    max_index = np.argsort(stat['delta'])[index]\n",
    "    index -= 1\n",
    "    correct_path = g.subgraph(stat['p'][max_index])\n",
    "    h_path = g.subgraph(stat['h_p'][max_index])\n",
    "    # continue\n",
    "    clusters = set()\n",
    "    for i in range(len(correct_path) - 1):\n",
    "        c1 = g.nodes()[stat['p'][max_index][i]]['cluster']\n",
    "        c2 = g.nodes()[stat['p'][max_index][i + 1]]['cluster']\n",
    "        clusters.add(c1)\n",
    "        if c1 != c2:\n",
    "            clusters = clusters.union(ad_mat[c1][c2])\n",
    "    for i in range(len(h_path) - 1):\n",
    "        c1 = g.nodes()[stat['h_p'][max_index][i]]['cluster']\n",
    "        c2 = g.nodes()[stat['h_p'][max_index][i + 1]]['cluster']\n",
    "        clusters.add(c1)\n",
    "        if c1 != c2:\n",
    "            clusters = clusters.union(ad_mat[c1][c2])\n",
    "\n",
    "    sub_graph = nx.Graph(extract_cluster_list_subgraph(g, clusters, cms))\n",
    "    cls = {}\n",
    "    counter = 0\n",
    "    for c in clusters:\n",
    "        cls[c] = counter\n",
    "        counter += 1\n",
    "    for u, d in sub_graph.nodes(data=True):\n",
    "        d['cluster'] = cls[d['cluster']]\n",
    "\n",
    "    pos_sub_graph = {u: (d['x'], d['y']) for u, d in sub_graph.nodes(data=True)}\n",
    "    pos_correct_path = {u: (d['x'], d['y']) for u, d in correct_path.nodes(data=True)}\n",
    "    pos_h_path = {u: (d['x'], d['y']) for u, d in h_path.nodes(data=True)}\n",
    "    pos_centers = {u: (d['x'], d['y']) for u, d in g1.nodes(data=True)}\n",
    "    # pos_G = {u: (d['x'], d['y']) for u, d in G.nodes(data=True)}\n",
    "\n",
    "    cmap = plt.get_cmap('plasma')\n",
    "    colors_sub_graph = [cmap(d['cluster'] / len(clusters)) for u, d in sub_graph.nodes(data=True)]\n",
    "    colors_sub_centers = [cmap(d['cluster'] / len(clusters)) for u, d in g1.nodes(data=True)]\n",
    "\n",
    "    fig, axs = plt.subplots(1, 1)\n",
    "    fig.set_figwidth(10)\n",
    "    fig.set_figheight(10)\n",
    "    e = stat['delta'][sorted[index + 1]]\n",
    "    axs.set_title(f'err: {e:.2f}')\n",
    "    label_dict = {u: d['cluster'] for u, d in sub_graph.nodes(data=True)}\n",
    "\n",
    "    nx.draw(sub_graph, ax=axs, node_size=50, pos=pos_sub_graph, alpha=0.5, node_color=colors_sub_graph)\n",
    "    # nx.draw(g1, ax=axs, node_size=50, pos=pos_centers, node_color='white')\n",
    "    nx.draw(correct_path, ax=axs, node_size=50, pos=pos_correct_path, node_color='red')\n",
    "    nx.draw(h_path, ax=axs, node_size=50, pos=pos_h_path, node_color='green')\n",
    "    pos_sub_graph = {u: (x + 0.0005, y) for u, (x, y) in pos_sub_graph.items()}\n",
    "    # nx.draw_networkx_labels(sub_graph, pos_sub_graph, labels=label_dict, font_size=15)\n",
    "    # nx.draw(H, ax=axs,node_size = 50, pos=pos_H, node_color = 'red', edge_color = 'green')\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "37c9199bd6441396",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
